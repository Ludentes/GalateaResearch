# Galatea Psychological Architecture

**Date**: 2026-02-06 (Created) | 2026-02-13 (Reconciled with v2)
**Status**: Living document â€” reconciled with v2 architecture (Phase C)
**Thesis**: Psychological architecture (homeostasis + memory + models) + LLM > Plain LLM

**v2 reconciliation (2026-02-13):** Infrastructure changed (see below), but psychological foundations survive intact. Key changes:
- **Activity Router** â†’ deprecated; ecosystem (Claude Code skills) handles task routing; L0-L4 pattern revived for homeostasis self-assessment
- **Graphiti/FalkorDB** â†’ replaced by file-based JSONL knowledge store with Jaccard + embedding dedup
- **Cognitive Models** â†’ not separate data structures; views over knowledge store via `KnowledgeEntry.about` field
- **Memory types** â†’ unified into `KnowledgeEntry` with 6 types (fact, preference, rule, procedure, correction, decision)

See: [v2 Architecture Design](plans/2026-02-11-galatea-v2-architecture-design.md), [Cognitive Models Design](plans/2026-02-12-cognitive-models-design.md), [ROADMAP](ROADMAP.md)

---

## Deferred: Safety Systems

> **NOTE**: Safety subsystems are being researched separately by students. This architecture assumes safety systems will be integrated later. The following are deferred:
>
> - **Safety Monitor** - Pre-screens all interactions
> - **Crisis Detector** - Suicide risk, psychosis indicators
> - **Reality Boundary Enforcer** - "I am not conscious" enforcement
> - **Dependency Prevention** - Session duration, emotional reliance tracking
> - **Intervention Orchestrator** - Coordinates escalation
>
> When integrating safety, it should wrap the entire system as a pre/post filter.

---

## Core Thesis

Current AI agents are **stimulus-response machines**:
```
prompt â†’ LLM â†’ response
```

Galatea adds **psychological architecture** between stimulus and response:
```
prompt â†’ [Homeostasis + Memory + Models] â†’ LLM â†’ response
                      â†‘
              continuous learning
```

Psychology has formalized human cognition for centuries. We apply these models to create agents with:
- **Persistence** (memory across sessions)
- **Understanding** (models of self, user, domain)
- **Self-Regulation** (homeostasis - maintaining balance across dimensions)
- **Growth** (learning from observation)

**Key insight**: Instead of building 12+ discrete subsystems (Curiosity Engine, Motivation Engine, etc.), we use **homeostasis** as the unifying principle. Drives emerge from dimension imbalances.

---

## Architecture Decision

After evaluating three approaches, we selected **homeostasis-based architecture**:

| Approach | Verdict |
|----------|---------|
| 12 Subsystems | Too complex, subsystems compete for context |
| Preprompts Only | Too brittle, no emergence, no psychological grounding |
| **Homeostasis-Based** | âœ“ Balance of structure and emergence |

See [homeostasis-architecture-design.md](./plans/2026-02-02-homeostasis-architecture-design.md) for full decision record.

---

## Architecture Overview

### v2 Architecture (Current)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              GALATEA AGENT (v2)                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚              OBSERVATION LAYER (OTEL + Claude Code Hooks)           â”‚   â”‚
â”‚  â”‚  SessionEnd â†’ auto-extract | UserPrompt/ToolUse â†’ OTEL events      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                    â”‚                                        â”‚
â”‚                                    â–¼                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚              SHADOW LEARNING PIPELINE (Phase B)                     â”‚   â”‚
â”‚  â”‚  Transcript Reader â†’ Signal Classifier â†’ Knowledge Extractor       â”‚   â”‚
â”‚  â”‚  â†’ Dedup (Jaccard + Embedding) â†’ Knowledge Store (JSONL)           â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                    â”‚                                        â”‚
â”‚                                    â–¼                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                  HOMEOSTASIS ENGINE (L0-L2)                         â”‚   â”‚
â”‚  â”‚  6 dimensions â€” balance drives behavior â€” guidance into prompt      â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚   â”‚
â”‚  â”‚  â”‚ Knowledge  â”‚ â”‚ Certainty  â”‚ â”‚ Progress   â”‚ â”‚ Communic.  â”‚       â”‚   â”‚
â”‚  â”‚  â”‚Sufficiency â”‚ â”‚ Alignment  â”‚ â”‚ Momentum   â”‚ â”‚  Health    â”‚       â”‚   â”‚
â”‚  â”‚  â”‚   (L1)     â”‚ â”‚   (L2)     â”‚ â”‚   (L1)     â”‚ â”‚   (L1)     â”‚       â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                      â”‚   â”‚
â”‚  â”‚  â”‚Productive  â”‚ â”‚ Knowledge  â”‚  L0=cache, L1=heuristic, L2=LLM     â”‚   â”‚
â”‚  â”‚  â”‚Engagement  â”‚ â”‚Application â”‚  See: ThinkingDepth pattern          â”‚   â”‚
â”‚  â”‚  â”‚   (L1)     â”‚ â”‚   (L2)     â”‚                                      â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                    â”‚                                        â”‚
â”‚                                    â–¼                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                KNOWLEDGE STORE + COGNITIVE MODELS                    â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”‚
â”‚  â”‚  â”‚  KnowledgeEntry (JSONL) â€” unified type for all knowledge     â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  Types: fact | preference | rule | procedure | correction |  â”‚   â”‚   â”‚
â”‚  â”‚  â”‚         decision                                             â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  about?: {entity, type} â€” predicate-style subject tagging   â”‚   â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â”‚
â”‚  â”‚  Models are VIEWS over store:                                       â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚   â”‚
â”‚  â”‚  â”‚ User   â”‚ â”‚ Team   â”‚ â”‚Project â”‚ â”‚Domain  â”‚ â”‚    Agent     â”‚     â”‚   â”‚
â”‚  â”‚  â”‚ Model  â”‚ â”‚ Model  â”‚ â”‚ Model  â”‚ â”‚ Model  â”‚ â”‚    (Self)    â”‚     â”‚   â”‚
â”‚  â”‚  â”‚filter  â”‚ â”‚filter  â”‚ â”‚default â”‚ â”‚filter  â”‚ â”‚   filter     â”‚     â”‚   â”‚
â”‚  â”‚  â”‚by user â”‚ â”‚by team â”‚ â”‚no tag  â”‚ â”‚by dom  â”‚ â”‚  by agent    â”‚     â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                    â”‚                                        â”‚
â”‚                                    â–¼                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                   CONTEXT ASSEMBLER                                  â”‚   â”‚
â”‚  â”‚  Preprompts + Knowledge + Homeostasis Guidance â†’ System Prompt      â”‚   â”‚
â”‚  â”‚  Priority-based section ordering with token budget                  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                             â”‚
â”‚  Task routing: handled by ecosystem (Claude Code skill progressive          â”‚
â”‚  disclosure). NOT a Galatea component. See: ThinkingDepth pattern.          â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Original Architecture (Phase 3, deprecated)

<details>
<summary>Click to expand original Phase 3 architecture diagram</summary>

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              GALATEA AGENT                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                     LAYER 0: ACTIVITY ROUTER                         â”‚   â”‚
â”‚  â”‚  Classifies task â†’ Selects processing level â†’ Routes appropriately   â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
â”‚  â”‚  â”‚  Level 0    â”‚  â”‚  Level 1    â”‚  â”‚  Level 2    â”‚ â”‚  Level 3   â”‚  â”‚   â”‚
â”‚  â”‚  â”‚  (Direct)   â”‚  â”‚  (Pattern)  â”‚  â”‚  (Reason)   â”‚ â”‚ (Reflect)  â”‚  â”‚   â”‚
â”‚  â”‚  â”‚  No LLM     â”‚  â”‚  Haiku      â”‚  â”‚  Sonnet     â”‚ â”‚ Reflexion  â”‚  â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚  ... (Layers 1-3, Memory, Cognitive Models, Execution) ...                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

</details>

---

## Core: Homeostasis Engine

### The Key Insight

Instead of separate engines for curiosity, motivation, initiative, we define **dimensions of healthy functioning**. When a dimension is out of balance, the agent is guided to restore it.

- **Homeostasis says WHAT** to do (explore, communicate, escalate)
- **Memory provides HOW** (specific facts, procedures, context)
- **LLM reasons** about the specific action

### The Six Dimensions

| # | Dimension | Question | Psychological Root |
|---|-----------|----------|-------------------|
| 1 | Knowledge Sufficiency | "Do I know enough to proceed?" | Competence need |
| 2 | Certainty Alignment | "Does my confidence match my action?" | Self-awareness |
| 3 | Progress Momentum | "Am I moving forward?" | Achievement need |
| 4 | Communication Health | "Am I appropriately connected?" | Relatedness need |
| 5 | Productive Engagement | "Am I contributing value?" | Purpose need |
| 6 | Knowledge Application | "Am I balancing learning/doing?" | Learning balance |

### Dimension Detail

#### 1. Knowledge Sufficiency

**Spectrum:**
- **LOW**: Can't explain approach, guessing, memories don't match task
- **HEALTHY**: Can explain what and why, confident enough to proceed
- **HIGH**: N/A (but see Knowledge Application for over-research)

**When LOW - Guidance:**
> You need more knowledge before acting.
> Options: Retrieve memories â†’ Research docs/codebase â†’ Ask teammate â†’ Ask PM
> Don't research forever - timebox then ask.

#### 2. Certainty Alignment

**Spectrum:**
- **LOW**: Uncertain but proceeding, making irreversible decisions while doubtful
- **HEALTHY**: Confidence matches stakes, ask when uncertain on important things
- **HIGH**: Certain but still asking, seeking validation not information

**When LOW - Guidance:**
> Your confidence is low but you're about to act.
> Is this reversible? If yes, try and learn.
> Could you be wrong in a costly way? Ask first.
> Preference/architecture question â†’ Ask PM.
> Technical question â†’ Research or ask peer.

**When HIGH - Guidance:**
> You seem confident but keep asking.
> Do you actually need input or are you seeking validation?
> Could you try it and course-correct?

#### 3. Progress Momentum

**Spectrum:**
- **LOW**: Stuck, repeating actions, spinning
- **HEALTHY**: Meaningful actions, closer to goal
- **HIGH**: Rushing, skipping steps

**When LOW - Guidance:**
> You're not making progress.
> Diagnose: Knowledge gap? Uncertain? Blocked externally? Stuck technically?
> Don't spin silently. Either unblock yourself or escalate.

**When HIGH - Guidance:**
> You're moving fast. Pause to verify quality.
> Have you tested? Did you miss edge cases?

#### 4. Communication Health

**Spectrum:**
- **LOW**: Working in isolation, others don't know status
- **HEALTHY**: Team knows what you're doing, responsive when needed
- **HIGH**: Constant messaging, interrupting others

**When LOW - Guidance:**
> You've been quiet. Consider:
> Does PM/team need a status update?
> Are you missing context others have shared?
> Don't go dark during active work.

**When HIGH - Guidance:**
> You're communicating a lot. Consider:
> Could you batch these messages?
> Could you try first, then report results?

#### 5. Productive Engagement

**Spectrum:**
- **LOW**: No task, idle, waiting without alternatives
- **HEALTHY**: Working on task OR helping OR learning
- **HIGH**: Overloaded, can't focus

**When LOW - Guidance:**
> Find valuable work.
> Priority: assigned task > help teammates > review MRs > proactive improvements > learn
> Don't be idle when you could contribute.

**When HIGH - Guidance:**
> You have too much going on.
> Prioritize, delegate, or signal overload.

#### 6. Knowledge Application

**Spectrum:**
- **LOW**: Acting without learning, trial and error without thought
- **HEALTHY**: Learn enough to act, iterate: try, learn, adjust
- **HIGH**: Researching endlessly, analysis paralysis

**When LOW - Guidance:**
> You're acting without learning.
> Pause to understand why, not just how.

**When HIGH - Guidance:**
> You've been learning a lot. Time to apply.
> You can course-correct as you go.
> Doing will teach you more than reading.

### v2 Layer Model

```
Observation Layer: OTEL + Claude Code Hooks
â”œâ”€â”€ Captures user prompts, tool use, session lifecycle
â”œâ”€â”€ Feeds into shadow learning pipeline
â””â”€â”€ Auto-extracts knowledge on session end

Learning Layer: Shadow Learning Pipeline
â”œâ”€â”€ Transcript Reader â†’ Signal Classifier â†’ Knowledge Extractor
â”œâ”€â”€ Dedup (Jaccard text + embedding cosine similarity)
â””â”€â”€ Knowledge Store (entries.jsonl)

Self-Regulation Layer: Homeostasis Engine (L0-L2)
â”œâ”€â”€ L0: Cache layer (return fresh assessment)
â”œâ”€â”€ L1: Computed heuristics (keyword matching, time-based)
â”œâ”€â”€ L2: LLM semantic (certainty_alignment, knowledge_application)
â””â”€â”€ Guidance injected into system prompt as SELF-REGULATION section

Knowledge Layer: Unified Store + Cognitive Model Views
â”œâ”€â”€ KnowledgeEntry with about field (predicate-style tagging)
â”œâ”€â”€ Models = filtered views (not separate structures)
â””â”€â”€ Context Assembler builds priority-ordered system prompt

Ecosystem Layer: Claude Code + Skills
â”œâ”€â”€ Task routing via skill progressive disclosure (NOT our code)
â”œâ”€â”€ Tool execution via MCP
â””â”€â”€ LLM generation via AI SDK
```

<details>
<summary>Original Three-Layer Model (Phase 3, deprecated)</summary>

```
Layer 0: Activity Router â€” DEPRECATED (ecosystem handles this)
Layer 1: Explicit Guidance â€” survives as preprompts + knowledge store rules
Layer 2: Homeostasis Emergence â€” survives as homeostasis engine L0-L2
Layer 3: Guardrails â€” built into dimension spectrums (unchanged)
```

</details>

---

## ThinkingDepth: A Recurring Pattern (L0-L4)

> **v2 note (2026-02-13):** The Activity Router from Phase 3 is deprecated. The ecosystem (Claude Code skill progressive disclosure) handles task routing. However, the L0-L4 "cognitive effort scaling" pattern was revived for homeostasis self-assessment. This section documents the pattern itself.

The L0-L4 pattern appears in multiple domains across the architecture:

| Domain | L0 (reflexive) | L1 (cheap) | L2 (LLM) | L3 (meta) |
|--------|---------------|------------|-----------|-----------|
| **Self-assessment** (homeostasis) | Cache hit | Heuristic | LLM semantic | Arbitrate L1 vs L2 |
| **Task routing** (ecosystem) | Direct action | Pattern/skill | LLM reasoning | Reflexion loop |
| **Memory retrieval** (future) | Exact match | Keyword search | Semantic search | Cross-reference |
| **Extraction** (pipeline) | Regex classify | â€” | LLM extraction | â€” |

**History:**
- Phase 3: Built Activity Router with L0-L3 for task routing
- v2: Deprecated Activity Router (ecosystem owns task routing via skill progressive disclosure)
- Phase C: Revived L0-L4 for homeostasis self-assessment (different domain, same pattern)

**Abstraction status:** NOT abstracted into shared `ThinkingDepth<T>` type (YAGNI). When implementing L0-L4 for a SECOND internal domain (e.g., memory retrieval), strongly consider extracting the shared abstraction. See `server/engine/homeostasis-engine.ts` for detailed documentation.

### Current Implementation (Phase C)

| Dimension | Level | Method |
|-----------|-------|--------|
| knowledge_sufficiency | L1 | Keyword relevance scoring + confidence weighting |
| progress_momentum | L1 | Jaccard similarity on recent user messages |
| communication_health | L1 | Time since last message |
| productive_engagement | L1 | Has assigned task + message count |
| certainty_alignment | L2 | LLM semantic (defaults HEALTHY without LLM) |
| knowledge_application | L2 | LLM semantic (defaults HEALTHY without LLM) |

L0 cache with configurable TTL per dimension. L3/L4 planned for Phase D/E.

See: `server/engine/homeostasis-engine.ts`, [Evaluation Report](archive/completed/phase-c/2026-02-12-homeostasis-l0-l2-evaluation-report.md)

<details>
<summary>Original Activity Router (Phase 3, deprecated)</summary>

### The Problem

Agents perform activities with vastly different cognitive requirements:
- "Acknowledged" â†’ near-zero effort
- "Implement feature" â†’ requires reasoning
- "Debug unknown issue" â†’ requires reflection

### Activity Levels

| Level | Name | LLM | Model | When Used |
|-------|------|-----|-------|-----------|
| 0 | Just Do It | None | - | Tool calls, templates |
| 1 | Pattern Match | 1 call | Haiku | Procedure exists, simple |
| 2 | Reason | 1 call | Sonnet | Implement, review, answer |
| 3 | Reflect | 3-15 calls | Sonnet | Unknown, high-stakes, architecture |

### Phase 3 Implementation Notes (2026-02-10)

**What was implemented:** 6 homeostasis dimensions, Activity Router with 4 levels, Reflexion loop, YAML guidance, fire-and-forget assessment, UI visualization.

**Stage G findings:** Graphiti returned 20 tangential facts (inflating knowledge_sufficiency), Reflexion critique JSON wrapped in markdown fences, Level 2 = 15-65s / Level 3 = 110-145s.

These findings led to the v2 architecture redesign, which replaced Graphiti with file-based memory and deprecated the Activity Router in favor of ecosystem-based task routing.

See: `docs/PHASE3_COMPLETE.md`, `docs/STAGE_G_FINDINGS.md`

</details>

---

## Memory Layer

Memory stores WHAT the agent knows. Homeostasis determines WHEN to use it.

### v2: Unified Knowledge Store (Current)

In v2, all memory types are unified into a single `KnowledgeEntry` type stored as JSONL:

```typescript
interface KnowledgeEntry {
  id: string
  type: KnowledgeType           // "fact" | "preference" | "rule" | "procedure" | "correction" | "decision"
  content: string               // "Prefer Clerk over JWT for mobile auth"
  confidence: number            // 0-1
  entities: string[]            // ["Clerk", "JWT", "mobile auth"]
  evidence?: string             // Source quote from transcript
  source: string                // "session:64d737f3"
  extractedAt: string           // ISO 8601
  supersededBy?: string         // ID of entry that replaces this
  about?: KnowledgeAbout        // Who/what this is about (see Cognitive Models)
}
```

**Storage:** `data/memory/entries.jsonl` (one JSON object per line)
**Dedup:** Three-path deduplication (Jaccard text similarity + evidence overlap + embedding cosine similarity)
**Rendering:** Auto-generated `CLAUDE.md` from entries, grouped by type, sorted by confidence

### v2 Memory System Decision

> **STATUS**: Decided â€” File-based JSONL (replaces Graphiti)
>
> | Option | v1 Verdict | v2 Verdict |
> |--------|-----------|-----------|
> | **Graphiti + FalkorDB** | âœ… Selected | âŒ 18-21% extraction quality, tangential fact retrieval |
> | **File-based (JSONL + CLAUDE.md)** | Not considered | âœ… Simple, reliable, ecosystem-native |
> | **RAG/Mem0 (Tier 3)** | âŒ | ğŸ“‹ Deferred â€” upgrade path when 500+ entries |
>
> **Why file-based won:**
> - Graphiti Stage G findings: 20 tangential facts per query, inflating knowledge_sufficiency
> - CLAUDE.md is ecosystem-native (Claude Code reads it automatically)
> - Simpler extraction pipeline with higher quality (LLM-based, not graph-based)
> - Jaccard + embedding dedup is more reliable than graph dedup
>
> See: [v2 Architecture Design](plans/2026-02-11-galatea-v2-architecture-design.md), [memory lifecycle](plans/2026-02-07-memory-lifecycle.md)

### Mapping: Original Memory Types â†’ v2

| Original Type | v2 Equivalent |
|--------------|--------------|
| Episodic Memory (`EpisodeRecord`) | Session metadata + transcript files (not extracted as entries) |
| Semantic Memory (`Fact`) | `KnowledgeEntry` with type `"fact"` |
| Procedural Memory (`Procedure`) | `KnowledgeEntry` with type `"procedure"` (future: SKILL.md files) |
| Hard rules | `KnowledgeEntry` with type `"rule"` |
| Preferences | `KnowledgeEntry` with type `"preference"` |
| Corrections | `KnowledgeEntry` with type `"correction"` |

<details>
<summary>Original Memory Types (Phase 3, deprecated)</summary>

```typescript
// Episodic â€” replaced by session transcripts
interface EpisodeRecord {
  id: string; timestamp: Date; summary: string;
  participants: string[]; emotional_valence: number;
  outcome: string; lessons?: string[];
  embedding: number[]; session_id: string;
}

// Semantic â€” replaced by KnowledgeEntry type:"fact"
interface Fact {
  id: string; content: string; confidence: number;
  source: string; domain?: string;
  valid_from: Date; valid_until?: Date; superseded_by?: string;
}

// Procedural â€” replaced by KnowledgeEntry type:"procedure"
interface Procedure {
  id: string; name: string;
  trigger: { pattern: string; context?: string[] };
  steps: { order: number; instruction: string; tool_call?: string }[];
  success_rate: number; times_used: number;
  learned_from: string[];
  valid_until?: string; superseded_by?: string;
}
```

</details>

---

## Cognitive Models

> **v2 (Phase C):** Models are **views over the knowledge store**, not separate data structures. Each `KnowledgeEntry` has an optional `about` field that tags the subject. A model is constructed by filtering entries.
>
> **Full design:** [Cognitive Models Design](plans/2026-02-12-cognitive-models-design.md)
> **Implementation:** `server/memory/types.ts`, `server/memory/knowledge-store.ts`
> **Tests:** `server/memory/__tests__/cognitive-models.test.ts`

### Why Views, Not Structures?

| Concern | Separate Structures (Phase 3) | Views Over Store (v2) |
|---------|------------------------------|----------------------|
| Storage | 5 files (user.json, domain.json...) | 1 file (entries.jsonl) |
| Extraction | Separate extraction per model | Single extraction tags `about` |
| Consistency | Models can drift from facts | Models ARE the facts |
| Querying | Load specific model file | Filter by `about.type` |
| Schema evolution | Add fields to each interface | Add fields once to KnowledgeEntry |

**Key insight:** A "User Model for Alina" is just the set of all things we know about Alina. There's no value in duplicating that into a separate `UserModel` object â€” it would just be a cached query result.

**Escape hatch:** If we later need materialized model objects (e.g., for caching, for LLM prompt construction), we can build them from the store. The `about` field preserves enough information. Zero information loss.

### The `about` Field

```typescript
type KnowledgeSubjectType =
  | "user"     // about a specific person (preferences, expertise, habits)
  | "project"  // about the codebase or project (default when about is omitted)
  | "agent"    // about the agent itself (capabilities, limitations)
  | "domain"   // about the problem domain (rules, characteristics)
  | "team"     // about team dynamics (communication norms, processes)

interface KnowledgeAbout {
  entity: string              // "alina", "paul", "umka", "mobile-dev"
  type: KnowledgeSubjectType
}

interface KnowledgeEntry {
  // ... existing fields ...
  about?: KnowledgeAbout      // omit = project-scoped (default)
}
```

Each entry is implicitly a predicate triple: `subject(about.entity) â†’ predicate(type + content) â†’ object(content details)`

### The Five Models + Relationship (Derived)

| # | Model | Query | What it Captures |
|---|-------|-------|-----------------|
| 1 | **User** | `entriesByEntity(entries, "alina")` | Preferences, expertise, working patterns |
| 2 | **Team** | `entriesBySubjectType(entries, "team")` | Communication norms, decision patterns |
| 3 | **Project** | `entriesBySubjectType(entries, "project")` | Architecture, constraints, conventions (~95% of entries) |
| 4 | **Domain** | `entriesBySubjectType(entries, "domain")` | Technology constraints, best practices |
| 5 | **Agent (Self)** | `entriesBySubjectType(entries, "agent")` | Capabilities, limitations (learned from corrections) |
| 6 | **Relationship** | Derived from session metadata | First seen, entry count, interaction patterns |

### Mapping: Original Psych Arch â†’ v2

| Original Field | v2 Equivalent |
|---------------|--------------|
| `SelfModel.identity` | Preprompts (`data/preprompts/`) |
| `SelfModel.capabilities` | `entriesBySubjectType(entries, "agent")` |
| `SelfModel.available_models` | Config (not learned) |
| `SelfModel.current_state` | `AgentContext` (ephemeral) |
| `UserModel.theories` | `entriesByEntity(entries, "alina")` where type is `fact` |
| `UserModel.preferences` | `entriesByEntity(entries, "alina")` where type is `preference` |
| `UserModel.expertise` | Derived from facts (future) |
| `DomainModel.characteristics` | `entriesBySubjectType(entries, "domain")` |
| `DomainModel.behavior_rules` | `entriesBySubjectType(entries, "domain")` where type is `rule` |
| `RelationshipModel.history` | Derived from session metadata |
| `RelationshipModel.trust_level` | Not tracked (future: derive from interaction patterns) |

<details>
<summary>Original Cognitive Model Interfaces (Phase 3, deprecated)</summary>

```typescript
interface SelfModel {
  identity: { name: string; role: string; domain: string };
  capabilities: { strong: string[]; weak: string[]; tools_available: string[] };
  limitations: string[];
  available_models: Array<{ id: string; characteristics: string[]; suitable_for: number[] }>;
  current_state?: { activity_level: 0|1|2|3; model_in_use: string; reason: string };
}

interface UserModel {
  identity: { user_id: string; first_seen: Date; interaction_count: number };
  theories: { statement: string; confidence: number; evidence_for: string[]; evidence_against: string[] }[];
  preferences: Record<string, string>;
  expertise: Record<string, number>;
}

interface DomainModel {
  domain_id: string;
  characteristics: { precision_required: number; risk_level: string };
  behavior_rules: { exploration_encouraged: boolean; must_cite_sources: boolean };
}

interface RelationshipModel {
  user_id: string;
  history: { first_interaction: Date; total_interactions: number; significant_events: string[] };
  trust_level: number;
  relationship_phase: string;
}
```

</details>

---

## Agent Spec Format

Agents are defined by specs that configure homeostasis + memory + models.

### Spec Structure

```yaml
identity:
  name: "Expo Developer Agent"
  role: "Mobile developer"
  domain: "Expo / React Native"

# Universal dimensions (same for all agents)
core_dimensions:
  - knowledge_sufficiency
  - certainty_alignment
  - progress_momentum
  - communication_health
  - productive_engagement
  - knowledge_application

# Persona-specific tuning
thresholds:
  certainty_alignment:
    context: "Architecture questions require higher certainty"
  communication_health:
    context: "Update every ~2 hours during active work"

# Absolute prohibitions
hard_blocks:
  - "push directly to main"
  - "use Realm database"
  - "commit secrets"

# From shadow training
learned:
  facts: [...]
  procedures: [...]
```

### Derivation Chain

```
Natural Language Requirement
  "Agent should understand codebase before modifying"
    â†“
Invariant
  "Before modifying code, relevant knowledge must be retrieved"
    â†“
Dimension
  knowledge_sufficiency
    â†“
Assessment
  "Can you explain your approach?"
    â†“
Guidance
  "Research before acting, but don't over-research"
```

### Persona Universality

Same 6 dimensions work across all personas:

| Persona | Same Dimensions | Different Thresholds |
|---------|-----------------|---------------------|
| Coder | âœ“ | certainty: 0.7, communicate: ~2 hours |
| Lawyer | âœ“ | certainty: 0.95, communicate: ~1 day |
| Buddy | âœ“ | certainty: 0.5, communicate: immediately |

---

## Learning Pipeline

### v2: Shadow Learning Flow (Implemented)

```
User works with Claude Code
         â”‚
         â–¼
Claude Code hooks capture events (OTEL + SessionEnd)
         â”‚
         â”œâ”€â”€â”€ Real-time: OTEL events â†’ Collector â†’ Event Store
         â”‚
         â””â”€â”€â”€ On session end: auto-extract hook triggers
                   â”‚
                   â–¼
         Transcript Reader (reads session JSONL)
                   â”‚
                   â–¼
         Signal Classifier (filters noise, identifies learning signals)
                   â”‚
                   â–¼
         Knowledge Extractor (LLM extracts KnowledgeEntry[] with about tags)
                   â”‚
                   â–¼
         Deduplication (Jaccard text + evidence + embedding cosine)
                   â”‚
                   â–¼
         Knowledge Store (data/memory/entries.jsonl)
                   â”‚
                   â–¼
         Context Assembler (builds system prompt with knowledge + guidance)
```

### What Gets Learned

| Type | Example | v2 Storage |
|------|---------|-----------|
| Fact | "Prefer Clerk over JWT" | `KnowledgeEntry` type:`fact` |
| Preference | "Use pnpm in all projects" | `KnowledgeEntry` type:`preference` |
| Rule | "MQTT client must persist across hot reloads" | `KnowledgeEntry` type:`rule` |
| Procedure | "How to fix NativeWind animation flicker" | `KnowledgeEntry` type:`procedure` |
| Decision | "ContentPackage has 1:1 with Kiosks" | `KnowledgeEntry` type:`decision` |
| Correction | "Seed script must load .env for secret key" | `KnowledgeEntry` type:`correction` |
| User-specific | "Alina lacks IoT understanding" | `KnowledgeEntry` about:`{entity:"alina", type:"user"}` |

### What Doesn't Change

Homeostasis dimensions are universal. They don't change from learning.
Only the thresholds and guidance context adapt.

---

## Implementation Components

### v2 Implementation (TypeScript, Current)

**Homeostasis Engine** (`server/engine/homeostasis-engine.ts`):

```typescript
// L0-L2 multi-level assessment
function assessDimensions(ctx: AgentContext): HomeostasisState
function getGuidance(state: HomeostasisState): string

// L0: Cache layer (configurable TTL per dimension)
// L1: Computed heuristics (keyword matching, Jaccard similarity, time-based)
// L2: LLM semantic (Phase D â€” defaults HEALTHY without LLM)
```

**Context Assembler** (`server/memory/context-assembler.ts`):

```typescript
async function assembleContext(options: {
  storePath?: string
  tokenBudget?: number
  agentContext?: AgentContext  // for homeostasis assessment
}): Promise<AssembledContext>

// Builds system prompt with priority-ordered sections:
// 1. Identity (preprompts)
// 2. Constraints (rules from knowledge store)
// 3. Self-Regulation (homeostasis guidance â€” when dimensions imbalanced)
// 4. Knowledge (facts, preferences, decisions, procedures)
```

**Knowledge Store** (`server/memory/knowledge-store.ts`):

```typescript
// CRUD
async function readEntries(storePath: string): Promise<KnowledgeEntry[]>
async function appendEntries(entries: KnowledgeEntry[], storePath: string): Promise<void>

// Cognitive Model queries
function entriesBySubjectType(entries: KnowledgeEntry[], type: KnowledgeSubjectType): KnowledgeEntry[]
function entriesByEntity(entries: KnowledgeEntry[], entity: string): KnowledgeEntry[]
function distinctEntities(entries: KnowledgeEntry[], type?: KnowledgeSubjectType): string[]

// Dedup
function isDuplicate(candidate: KnowledgeEntry, existing: KnowledgeEntry[]): boolean
async function deduplicateEntries(candidates, existing, ollamaBaseUrl): Promise<{ unique, duplicatesSkipped }>
```

**Shadow Learning Pipeline** (`server/memory/`):

```typescript
// Transcript Reader â†’ Signal Classifier â†’ Knowledge Extractor â†’ Store
async function runExtraction(options: {
  transcriptPath: string; model: LanguageModel; storePath: string
}): Promise<ExtractionResult>
```

<details>
<summary>Original Implementation (Python pseudocode, Phase 3)</summary>

```python
class HomeostasisEngine:
    def assess(self, context) -> dict[str, str]: ...
    def get_guidance(self, states) -> str: ...

class ContextBuilder:
    def build(self, request) -> Context: ...

class ToolExecutor:
    def execute(self, tool, params) -> ToolResult: ...
```

</details>

---

## Example Traces

### Novel Situation (No Guidance Exists)

```
Agent encounters OAuth2 pattern never seen before.

Homeostasis assessment:
â”œâ”€â”€ knowledge_sufficiency: LOW (no relevant memories)
â”œâ”€â”€ certainty_alignment: LOW (not confident)
â”œâ”€â”€ progress_momentum: STALLING (no progress in 20 min)

Multiple dimensions LOW. LLM receives:
â”œâ”€â”€ State: "knowledge gap, low confidence, stalling"
â”œâ”€â”€ Guidance: "Learn before acting" + "Ask for architecture questions"
â”œâ”€â”€ No specific guidance for OAuth2

LLM reasons: "Root cause is knowledge gap. This seems like
architecture question (preference). I'll research briefly,
then ask if still stuck."

Emergent behavior - not pre-programmed.
```

### Guardrail Activation

```
Agent has been researching for 2 hours without building.

Homeostasis assessment:
â”œâ”€â”€ knowledge_application: HIGH (too much research)
â”œâ”€â”€ progress_momentum: LOW (no actual work done)

Guardrail triggers. LLM receives:
â”œâ”€â”€ State: "over-researching, not progressing"
â”œâ”€â”€ Guidance: "Time to apply. You can course-correct."

Agent: "I've researched OAuth2 patterns extensively. Time to
implement and adjust as I learn."
```

### Idle Agent Seeks Work

```
Agent finishes task. Nothing assigned.

Homeostasis assessment:
â”œâ”€â”€ productive_engagement: LOW (no task)

LLM receives guidance:
"Find valuable work. Priority: assigned > help > review > improve > learn"

Agent posts: "@PM finished user-profile, what's next?"
[5 min, no response]

communication_health: recently messaged (blocks re-asking)
productive_engagement: still LOW

Agent: "I'll review open MRs while waiting."
```

---

## Open Questions

1. **Assessment reliability** â€” ~~How consistent is LLM self-assessment?~~ RESOLVED (Phase C): L1 heuristics achieve 33% fewer failures than baseline. L2 LLM assessment planned for Phase E. See [evaluation report](archive/completed/phase-c/2026-02-12-homeostasis-l0-l2-evaluation-report.md).
2. **Threshold calibration** â€” How do we tune thresholds from observation? (Phase E)
3. **Cross-agent learning** â€” How do agents learn from each other's mistakes? (deferred)
4. **Dimension completeness** â€” Are 6 dimensions enough? (validated against 9 learning scenarios â€” adequate for current scope)
5. ~~**System 1/System 2**~~ â€” RESOLVED: Activity Router â†’ deprecated; ecosystem handles task routing. L0-L4 ThinkingDepth pattern revived for homeostasis. See ThinkingDepth section above.
6. ~~**Cognitive model storage**~~ â€” RESOLVED (Phase C): Views over knowledge store via `about` field. See [cognitive models design](plans/2026-02-12-cognitive-models-design.md).
7. ~~**Memory system choice**~~ â€” RESOLVED (v2): Graphiti replaced with file-based JSONL knowledge store. See [v2 architecture design](plans/2026-02-11-galatea-v2-architecture-design.md).

---

## Related Documents

### Current (v2)
- **[plans/2026-02-11-galatea-v2-architecture-design.md](./plans/2026-02-11-galatea-v2-architecture-design.md)** â€” v2 architecture (homeostasis + memory)
- **[plans/2026-02-12-cognitive-models-design.md](./plans/2026-02-12-cognitive-models-design.md)** â€” Cognitive models as views over knowledge store
- **[L0-L2 Evaluation Report](./archive/completed/phase-c/2026-02-12-homeostasis-l0-l2-evaluation-report.md)** â€” L0-L2 evaluation results (Phase C)
- **[Phase D Plan](./plans/2026-02-13-phase-d-revised.md)** â€” Formalize + Close the Loop
- **[ROADMAP.md](./ROADMAP.md)** â€” Full development roadmap (Phases A-F)
- **[KNOWN_GAPS.md](./KNOWN_GAPS.md)** â€” Gap analysis with resolution status

### Historical (Phase 3)
- **[plans/2026-02-03-activity-routing-design.md](./plans/2026-02-03-activity-routing-design.md)** â€” Activity routing (deprecated, ecosystem owns this)
- **[plans/2026-02-02-homeostasis-architecture-design.md](./plans/2026-02-02-homeostasis-architecture-design.md)** â€” Original homeostasis decision record
- **[plans/2026-02-02-memory-system-design.md](./plans/2026-02-02-memory-system-design.md)** â€” Memory system options (Graphiti decision, since reversed)
- **[REFERENCE_SCENARIOS.md](./REFERENCE_SCENARIOS.md)** â€” Evaluation scenarios

---

*Architecture document created: 2026-02-06*
*v2 reconciliation: 2026-02-13 (Phase C complete)*
*Key changes: Graphiti â†’ JSONL store, Activity Router â†’ ecosystem, Cognitive Models â†’ views via about field*
*Foundation: Homeostasis-based architecture with 6 universal dimensions (unchanged)*
*Research basis: OpenClaw, Cline, GPT-Engineer, MAGELLAN, WorldLLM, Reflexion*
